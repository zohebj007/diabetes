{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from datetime import datetime\n",
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "from sagemaker import Session\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "# Define your S3 bucket and prefix\n",
    "bucket = 'diabates'\n",
    "prefix = 'pipeline'\n",
    "region = 'ap-south-1'\n",
    "input_source = f\"s3://{bucket}/datasets/diabetes.csv\"\n",
    "train_path = f\"s3://{bucket}/{prefix}/train\"\n",
    "test_path = f\"s3://{bucket}/{prefix}/test\"\n",
    "val_path = f\"s3://{bucket}/{prefix}/val\"\n",
    "\n",
    "# Generate a timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # Format: YYYYMMDD-HHMMSS\n",
    "#model_output_uri\n",
    "model_output_uri = f\"s3://{bucket}/{prefix}/pipeline_run_version_{timestamp}\"\n",
    "\n",
    "train_input = TrainingInput(s3_data=train_path, content_type='text/csv')\n",
    "evaluation_output_uri = evaluation_output_uri = f\"s3://{bucket}/output/evaluation\"\n",
    "\n",
    "######instances-require for the pipeline###\n",
    "\n",
    "processing_image_uri = image_uris.retrieve(framework='sklearn', region=region, version='1.0-1')\n",
    "training_image_uri = image_uris.retrieve(framework='sklearn', region=region, version='1.0-1')\n",
    "evaluation_image_uri = image_uris.retrieve(framework='sklearn', region=region, version='1.0-1')\n",
    "instance_count = 1\n",
    "instance_type = 'ml.m5.xlarge'\n",
    "\n",
    "\n",
    "################# important for pipeline #####################\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = 'arn:aws:iam::590183717898:role/service-role/AmazonSageMaker-ExecutionRole-20240716T105741'  #sagemaker.get_execution_role()\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor,  # Use ScriptProcessor if you are using a script\n",
    ")\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# Create a ScriptProcessor\n",
    "sklearn_processor = ScriptProcessor(\n",
    "    image_uri=processing_image_uri,\n",
    "    role=role,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1, \n",
    "    base_job_name='diabetes_new',\n",
    "    command=['python3'],\n",
    ")\n",
    "\n",
    "# Define processing step\n",
    "processing_step = ProcessingStep(\n",
    "    name='PreprocessingStep',\n",
    "    processor=sklearn_processor,\n",
    "    code='preprocess.py',  # Path to your preprocessing script\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_source, \n",
    "            destination=\"/opt/ml/processing/input\",\n",
    "            s3_input_mode=\"File\",\n",
    "            s3_data_distribution_type=\"ShardedByS3Key\",\n",
    "            \n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train_data\", \n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            destination=train_path,\n",
    "            s3_upload_mode=\"EndOfJob\",\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test_data\", \n",
    "            source=\"/opt/ml/processing/output/test\",\n",
    "            destination=test_path,\n",
    "            s3_upload_mode=\"EndOfJob\",\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"val_data\", \n",
    "            source=\"/opt/ml/processing/output/validation\",\n",
    "            destination=val_path,\n",
    "            s3_upload_mode=\"EndOfJob\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the input data for training\n",
    "train_input = TrainingInput(s3_data=train_path, content_type='text/csv')\n",
    "\n",
    "# Define the Estimator\n",
    "estimator = Estimator(\n",
    "    entry_point='train.py',  # Your training script\n",
    "    image_uri=training_image_uri,\n",
    "    py_version='py3',\n",
    "    instance_type=instance_type,  # Specify the instance type\n",
    "    instance_count=instance_count,  # Set the instance count\n",
    "    role=role,\n",
    "    output_path=model_output_uri,  # This should include the timestamp\n",
    "    base_job_name='sklearn-diabetes',  # Update base job name if needed\n",
    "    hyperparameters={\n",
    "        'n_estimators': 50,\n",
    "        'max_depth': 5\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define the training step\n",
    "train_step = TrainingStep(\n",
    "    name=\"TrainModel\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"training\": train_input,\n",
    "    },\n",
    ")\n",
    "\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor,\n",
    ")\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "##### train artifacts ######\n",
    "#model_artifact_path = train_step.properties.ModelArtifacts.S3ModelArtifacts\n",
    "model_artifact_path = train_step.properties.ModelArtifacts.S3ModelArtifacts\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "# Initialize the ScriptProcessor\n",
    "evaluation_processor = ScriptProcessor(\n",
    "    image_uri=evaluation_image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=instance_type,\n",
    "    instance_count=instance_count,\n",
    "    role=role,  # Replace with your actual role ARN\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "# Define the processing step for evaluation\n",
    "evaluation_step = ProcessingStep(\n",
    "    name=\"EvaluateModel\",\n",
    "    processor=evaluation_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=model_artifact_path, destination=\"/opt/ml/processing/model\"),\n",
    "        ProcessingInput(source=test_path, destination=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/output\", destination=evaluation_output_uri),\n",
    "    ],\n",
    "    code=\"eval.py\",\n",
    "    property_files=[evaluation_report]\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "'''pipeline = Pipeline(\n",
    "    name='DiabetestrainingPipeline-4',\n",
    "    steps=[train_step]  # Include the training step\n",
    ")\n",
    "\n",
    "# Create and start the pipeline\n",
    "pipeline.create(role_arn=role)  # Creates the pipeline\n",
    "pipeline.start()  # Starts the pipeline execution'''\n",
    "\n",
    "\n",
    "####registerstep########\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThan\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=f\"{evaluation_output_uri}/evaluation.json\",\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "container = image_uris.retrieve(region=aws_region, framework='xgboost', version='0.90-1')\n",
    "model = Model(\n",
    "    image_uri=container,\n",
    "    model_data=model_artifact_path,\n",
    "    role=role,  # Replace with your actual role ARN\n",
    "    sagemaker_session=pipeline_session  # Attach the pipeline session here\n",
    ")\n",
    "\n",
    "register_args = model.register(\n",
    "    content_types=[\"application/x-model\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=\"diabates-main-structured\",  # Specify the model group name here\n",
    "    model_metrics=model_metrics  # Optional: Attach model metrics\n",
    ")\n",
    "step_register = ModelStep(name=\"diabates-main-structured\", step_args=register_args)\n",
    "\n",
    "\n",
    "# Define the condition to check accuracy\n",
    "cond_gte = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluation_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"accuracy\"\n",
    "    ),\n",
    "    right=0.60\n",
    ")\n",
    "\n",
    "# Create a condition step\n",
    "condition_step = ConditionStep(\n",
    "    name=\"CheckAccuracy\",\n",
    "    conditions=[cond_gte],\n",
    "    if_steps=[step_register],  # Register the model if accuracy > 60%\n",
    "    else_steps=[]  # Do nothing if the accuracy is <= 60%\n",
    ")\n",
    "\n",
    "train_step.add_depends_on([processing_step])\n",
    "evaluation_step.add_depends_on([train_step])\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name='DiabetesEndpointPipeline-2',\n",
    "    steps=[processing_step, train_step, evaluation_step, condition_step]  # Include the training step\n",
    ")\n",
    "\n",
    "# Create and start the pipeline\n",
    "pipeline.create(role_arn=role)  # Creates the pipeline\n",
    "pipeline.start()  # Starts the pipeline execution\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
